train_dir <- "../data/train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="")
info <- read.csv("/Users/zhaoziqin/Desktop/project3/data/train_set/label.csv")
##### set up parameters，eg:cross-validation, K-fold，whether or not to do the train/test
run.cv=TRUE # run cross-validation on the training set
K <- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set
n<-length(fiducial_pt_list)
# Test partial part
# n<-n*0.3
# index<-sample(1:length(fiducial_pt_list),n,replace=F)
# n_train <- round(n*(4/5), 0)
# train_idx <- sample(index, n_train, replace = F)
# test_idx <- setdiff(index,train_idx)
############拆分train test（通过train_idx）###########
n_train <- round(n*(4/5), 0)
train_idx <- sample(1:n, n_train, replace = F)
test_idx <- setdiff(1:n,train_idx)
source("/Users/zhaoziqin/Desktop/project3/lib/feature.R")
# dat_train to get all distances from two points from images in train_idx，total points (78*77=6006)
tm_feature_train <- NA
if(run.feature.train){
tm_feature_train <- system.time(dat_train <- feature(fiducial_pt_list, train_idx))
}
# data_test
tm_feature_test <- NA
if(run.feature.test){
tm_feature_test <- system.time(dat_test <- feature(fiducial_pt_list, test_idx))
}
# save(dat_train, file="../output/feature_train.RData")
# save(dat_test, file="../output/feature_test.RData")
data=dat_train[sample(1:2000,500,replace = F),]
n.tree= 100
shrinkage=0.05
inter.dep =1
cv.folds=3
# distribution="adaboost"    #some problem
distribution = "multinomial"
n1<-Sys.time()
# fit initial model
gbm1 <-
gbm(emotion_idx ~.,            # formula
data=data,                   # dataset
# var.monotone=c(0,0,0,0,0,0), # -1: monotone decrease,
#                              # +1: monotone increase,
#                              #  0: no monotone restrictions
distribution = "multinomial",   # see the help for other choices
n.trees=n.tree,              # number of trees
shrinkage=shrinkage,         # shrinkage or learning rate,
# 0.001 to 0.1 usually work
interaction.depth=inter.dep, # 1: additive model, 2: two-way interactions, etc.
bag.fraction = 0.5,          # subsampling fraction, 0.5 is probably best
train.fraction = 0.5,        # fraction of data for training,
# first train.fraction*N used for training
n.minobsinnode = 10,         # minimum total weight needed in each node
cv.folds = cv.folds,                # do 3-fold cross-validation
keep.data=TRUE,              # keep a copy of the dataset with the object
verbose=FALSE,               # don't print out progress
n.cores=1)                   # use only a single core (detecting #cores is
# error-prone, so avoided here)
n2<-Sys.time()-n1
save(gbm1,file="../output/baseline.RData")
save(gbm1,file="/Users/zhaoziqin/Desktop/project3/output/baseline.RData")
# # check performance using a 50% heldout test set
best.iter_test <- gbm.perf(gbm1,method="test")
# # check performance using 5-fold cross-validation
best.iter_cv <- gbm.perf(gbm1,method="cv")
# predict on the new data using "best" number of trees
# f.predict generally will be on the canonical scale (logit,log,etc.)
best.iter<-c(best.iter_test,best.iter_cv)
table<-NULL
for (i in best.iter){
pred = predict.gbm(object = gbm1,
newdata = dat_test,
n.trees = i,
type = "response")
labels = colnames(pred)[apply(pred, 1, which.max)]
# least squares error
result = data.frame(dat_test$emotion_idx, labels)
acc<-mean(dat_test$emotion_idx==labels)
table<-rbind(table,tibble(acc=acc))
}
# predict on the new data using "best" number of trees
# f.predict generally will be on the canonical scale (logit,log,etc.)
best.iter<-c(best.iter_test,best.iter_cv)
table<-NULL
for (i in best.iter){
pred = predict.gbm(object = gbm1,
newdata = dat_test,
n.trees = i,
type = "response")
labels = colnames(pred)[apply(pred, 1, which.max)]
# least squares error
result = data.frame(dat_test$emotion_idx, labels)
acc<-mean(dat_test$emotion_idx==labels)
table<-rbind(table,tibble(acc=acc))
}
table
best.iter_test
best.iter_cv
# # check performance using a 50% heldout test set
best.iter_test <- gbm.perf(gbm1,method="test")
# # check performance using 5-fold cross-validation
best.iter_cv <- gbm.perf(gbm1,method="cv")
load("~/Desktop/baseline.RData")
View(gbm1)
View(gbm1)
plot(x,2*(1-cos(12*x)))
x = seq(0.2*pi,0.001)
plot(x,2*(1-cos(12*x)))
x = seq(0.2*pi,0.001)
plot(x,2*(1-cos(12*x)),type='1')
x = seq(0.2*pi,0.001)
plot(x,2*(1-cos(12*x)),type='l')
x = seq(0.2*pi,0.001)
plot(x,2*(1-cos(12*x)),type='l')
x = seq(0.2*pi,0.001)
plot(x,2*(1-cos(12*x)),type='l')
x = seq(0,2*pi,0.001)
plot(x,2*(1-cos(12*x)),type='l')
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
source("../lib/Matrix_Factorization.R")
result_summary_sgd_5000 <- array(NA, dim = c(nrow(f_l), 10, 4))
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
result_summary_sgd_5000 <- array(NA, dim = c(nrow(f_l), 10, 4))
run_time <- system.time(for(i in 1:nrow(f_l)){
par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
cat(par, "\n")
current_result <- cv.function(data[1:5000,], K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
result_summary_sgd_5000[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T)
print(result_summary_sgd_5000)
})
source("../lib/cross_validation.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
result_summary_sgd_5000 <- array(NA, dim = c(nrow(f_l), 10, 4))
run_time <- system.time(for(i in 1:nrow(f_l)){
par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
cat(par, "\n")
current_result <- cv.function(data[1:5000,], K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
result_summary_sgd_5000[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T)
print(result_summary_sgd_5000)
})
source("../lib/cross_validation_r1+r2.R")
source("../lib/cross_validation_R1+R2.R")
source("../lib/cross_validation_A1+R1+R2.R")
source("../lib/Matrix_Factorization_A1+R1+R2.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
result_summary_r12 <- array(NA, dim = c(nrow(f_l), 10, 4))
run_time <- system.time(for(i in 1:nrow(f_l)){
par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
cat(par, "\n")
current_result <- cv.function.r12(data[1:5000,], K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
result_summary_r12[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T)
print(result_summary_r12)
})
save(result_summary_r12, file = "../output/rmseR12.Rdata")
rmse <- data.frame(rbind(t(result_summary_r12[1,,]), t(result_summary_r12[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
knitr::opts_chunk$set(echo = TRUE)
library(dplyr)
library(tidyr)
library(ggplot2)
library(coop)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
source("../lib/Matrix_Factorization.R")
source("../lib/cross_validation_A1+R1+R2.R")
source("../lib/Matrix_Factorization_A1+R1+R2.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
# use cross validation to get the rmse
#result_summary_r12 <- array(NA, dim = c(nrow(f_l), 10, 4))
#run_time <- system.time(for(i in 1:nrow(f_l)){
#    par <- paste("f = ", f_l[i,1], ", lambda = ", 10^f_l[i,2])
#    cat(par, "\n")
#    current_result <- cv.function.r12(data[1:5000,], K = 5, f = f_l[i,1], lambda = 10^f_l[i,2])
#    result_summary_r12[,,i] <- matrix(unlist(current_result), ncol = 10, byrow = T)
#    print(result_summary_r12)
#})
#save(result_summary_r12, file = "../output/rmseR12.Rdata")
load(file = "../output/rmseR12.Rdata")
rmse <- data.frame(rbind(t(result_summary_r12[1,,]), t(result_summary_r12[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
set.seed(0)
#get the subset of train set and test set from the first 5000 data
test_idx2 <- sample(1:5000, 5000/5, 0)
train_idx2 <- setdiff(1:5000, test_idx2)
data_train2 <- data[train_idx2,]
data_test2 <- data[test_idx2,]
# resultr12 <- gradesc.r12(f = 10, lambda = 0.1,lrate = 0.01, max.iter = 100, stopping.deriv = 0.01,data = data2, train = data_train2, test = data_test2)
# save(resultr12, file = "../output/mat_facR12.RData")
load(file = "../output/mat_facR12.RData")
result<-resultr12
train<-data_train2
dim(result$p)
dim(result$q)
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result12) # Rating after applying KNN
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
# KNN_Rating <- KNN.post(resultr12) # Rating after applying knn
Rating <- t(resultr12$p)%*%(resultr12$q)  # Rating without knn
#Knn_Rating: (32*2427: the number in the matrix is the score of ratings)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
# train mse with knn is the same as mse without knn.
# KNN_Rating <- KNN.post(resultr12) # Rating after applying knn
Rating <- t(result$p)%*%(result$q)  # Rating without knn
#Knn_Rating: (32*2427: the number in the matrix is the score of ratings)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
# train mse with knn is the same as mse without knn.
library(tidyverse)
library(MASS)
library(coop)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
source("../lib/cross_validation_pmf.R")
source("../lib/Matrix_Factorization_pmf.R")
f_list <- c(10,20,10,20)
lp_list <- c(1,1,0.5,0.5)
lq_list <- c(1,1,0.5,0.5)
f_l = cbind(f_list,lp_list,lq_list)
load(file = "../output/rmse_pmf.Rdata")
rmse_pmf <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", sigma_p = ", f_l[,2], ", sigma_q = ", f_l[,3]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse_pmf$epoch <- as.numeric(gsub("X", "", rmse_pmf$epoch))
rmse_pmf %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
set.seed(0)
#get the subset of train set and test set from the first 5000 data
test_idx2 <- sample(1:5000, 5000/5, 0)
train_idx2 <- setdiff(1:5000, test_idx2)
data_train2 <- data[train_idx2,]
data_test2 <- data[test_idx2,]
load(file = "../output/mat_fac_pmf.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
Rating <- t(result$p)%*%(result$q)  # Rating without KNN
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A2_chart<-tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A2_chart
#A2
RMSE <- data.frame(epochs = seq(20, 100, 20), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)
RMSE %>% ggplot(aes(x = rep(seq(20, 100, 20),2), y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(20, 100, 20)) + xlim(c(0, 100))+
labs(x = "epochs",  title = "A2")
library(dplyr)
library(tidyr)
library(ggplot2)
library(coop)
library(tidyverse)
library(MASS)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
source("../lib/cross_validation_A1+R1+R2.R")
source("../lib/Matrix_Factorization_A1+R1+R2.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
load(file = "../output/rmseR12.Rdata")
rmse <- data.frame(rbind(t(result_summary_r12[1,,]), t(result_summary_r12[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
source("../lib/cross_validation_pmf.R")
source("../lib/Matrix_Factorization_pmf.R")
f_list <- c(10,20,10,20)
lp_list <- c(1,1,0.5,0.5)
lq_list <- c(1,1,0.5,0.5)
f_l = cbind(f_list,lp_list,lq_list)
load(file = "../output/rmse_pmf.Rdata")
rmse_pmf <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", sigma_p = ", f_l[,2], ", sigma_q = ", f_l[,3]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse_pmf$epoch <- as.numeric(gsub("X", "", rmse_pmf$epoch))
rmse_pmf %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
set.seed(0)
#get the subset of train set and test set from the first 5000 data
test_idx2 <- sample(1:5000, 5000/5, 0)
train_idx2 <- setdiff(1:5000, test_idx2)
data_train2 <- data[train_idx2,]
data_test2 <- data[test_idx2,]
load(file = "../output/mat_facR12.RData")
result<-resultr12
train<-data_train2
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
Rating <- t(result$p)%*%(result$q)  # Rating without knn
#Knn_Rating: (32*2427: the number in the matrix is the score of ratings)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
# train mse with knn is the same as mse without knn.
result <- gradesc_pmf(f = 10, sigma_p = 0.5,sigma_q = 0.5, lrate = 0.01, max.iter = 100, stopping.deriv = 0.01, data = data[1:5000,], train = data_train2, test = data_test2)
load(file = "../output/mat_fac_pmf.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
Rating <- t(result$p)%*%(result$q)  # Rating without KNN
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A1_chart <- tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A1_chart
# train mse with knn is the same as mse without knn.
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A2_chart<-tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A2_chart
load(file = "../output/mat_facR12.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result12) # Rating after applying KNN
load(file = "../output/mat_facR12.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, resultr12) # Rating after applying KNN
Rating <- t(resultr12$p)%*%(resultr12$q)  # Rating without knn
#Knn_Rating: (32*2427: the number in the matrix is the score of ratings)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A1_chart <- tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A1_chart
# train mse with knn is the same as mse without knn.
library(dplyr)
library(tidyr)
library(ggplot2)
library(coop)
library(tidyverse)
library(MASS)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
source("../lib/cross_validation_A1+R1+R2.R")
source("../lib/Matrix_Factorization_A1+R1+R2.R")
f_list <- seq(10, 20, 10)
l_list <- seq(-2, -1, 1)
f_l <- expand.grid(f_list, l_list)
load(file = "../output/rmseR12.Rdata")
rmse <- data.frame(rbind(t(result_summary_r12[1,,]), t(result_summary_r12[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", lambda = ", 10^f_l[,2]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse$epoch <- as.numeric(gsub("X", "", rmse$epoch))
rmse %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
source("../lib/cross_validation_pmf.R")
source("../lib/Matrix_Factorization_pmf.R")
f_list <- c(10,20,10,20)
lp_list <- c(1,1,0.5,0.5)
lq_list <- c(1,1,0.5,0.5)
f_l = cbind(f_list,lp_list,lq_list)
load(file = "../output/rmse_pmf.Rdata")
rmse_pmf <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", sigma_p = ", f_l[,2], ", sigma_q = ", f_l[,3]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse_pmf$epoch <- as.numeric(gsub("X", "", rmse_pmf$epoch))
rmse_pmf %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
set.seed(0)
#get the subset of train set and test set from the first 5000 data
test_idx2 <- sample(1:5000, 5000/5, 0)
train_idx2 <- setdiff(1:5000, test_idx2)
data_train2 <- data[train_idx2,]
data_test2 <- data[test_idx2,]
load(file = "../output/mat_facR12.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, resultr12) # Rating after applying KNN
Rating <- t(resultr12$p)%*%(resultr12$q)  # Rating without knn
#Knn_Rating: (32*2427: the number in the matrix is the score of ratings)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A1_chart <- tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A1_chart
# train mse with knn is the same as mse without knn.
load(file = "../output/mat_fac_pmf.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
View(result)
View(result)
View(result)
Rating <- t(result$p)%*%(result$q)  # Rating without KNN
View(resultr12)
View(resultr12)
RMSE <- function(rating, est_rating){
sqr_err <- function(obs){
sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
return(sqr_error)
}
return(sqrt(mean(apply(rating, 1, sqr_err))))
}
A2_chart<-tibble(rating=c("Without KNN","With KNN"),
train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),
test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A2_chart
RMSE <- data.frame(epochs = seq(20, 100, 20), Training_MSE = resultr12$train_RMSE, Test_MSE = resultr12$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)
RMSE %>% ggplot(aes(x = rep(seq(20, 100, 20),2), y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(20, 100, 20)) + xlim(c(0, 100))+
labs(x = "epochs",  title = "A1+R1+R2")
RMSE <- data.frame(epochs = seq(20, 100, 20), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)
RMSE %>% ggplot(aes(x = rep(seq(20, 100, 20),2), y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(20, 100, 20)) + xlim(c(0, 100))+
labs(x = "epochs",  title = "A2")
RMSE <- data.frame(epochs = seq(10, 100, 10),
Training_MSE = resultr12$train_RMSE,
Test_MSE = resultr12$test_RMSE) %>%
gather(key = train_or_test, value = RMSE, -epochs)
RMSE %>% ggplot(aes(x = epochs, y = RMSE,col = train_or_test)) +
geom_point() +
scale_x_discrete(limits = seq(10, 100, 10)) +
xlim(c(0, 100))+
labs(x = "epochs",  title = "A1+R1+R2")
