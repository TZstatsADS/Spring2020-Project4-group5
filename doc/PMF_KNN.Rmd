---
title: "A1 + P2"
author: "Jiadong Wu, Kaiqi Wang"
date: "4/15/2020"
output: pdf_document
---

# Project 4 --- Part II (A1 + P2)

Algorithm : Gradient Descent With Probabilistic Assumption (A2)

Regularization : None

Postprocessing : SVD with KNN (P2)

### Step 1 Load Data and Train-test Split
```{r warning=FALSE, message=FALSE}
library(tidyverse)
library(MASS)
library(coop)
data <- read.csv("../data/ml-latest-small/ratings.csv")
set.seed(0)
test_idx <- sample(1:nrow(data), round(nrow(data)/5, 0))
train_idx <- setdiff(1:nrow(data), test_idx)
data_train <- data[train_idx,]
data_test <- data[test_idx,]
```

###Step 2 Matrix Factorization
#### Step 2.1 A2 (Probabilistic Matrix Factorization)
```{r}
U <- length(unique(data[1:5000,]$userId))
I <- length(unique(data[1:5000,]$movieId))
```

#### Step 2.2 Parameter Tuning

# Plot our tunning parameters for A2 (only 5000 rows)

```{r}
source("../lib/cross_validation_pmf.R")  
source("../lib/Matrix_Factorization_pmf.R")

f_list <- c(10,20,10,20)
lp_list <- c(1,1,0.5,0.5)
lq_list <- c(1,1,0.5,0.5) 
f_l = cbind(f_list,lp_list,lq_list)
```

```{r eval=FALSE}
#cross-validation with K = 5
result_summary <- array(NA, dim = c(nrow(f_l), 5, 4)) 
run_time <- system.time(for(i in 1:nrow(f_l)){
    par <- paste("f = ", f_l[i,1], ", sigma_p = ", f_l[i,2],", sigma_q = ", f_l[i,3])
    cat(par, "\n")
    current_result <- cv.function_pmf(data[1:5000,], K = 5, f = f_l[i,1],sigma_p=f_l[i,2],sigma_q= f_l[i,3],sigma = 0.1)
    result_summary[,,i] <- matrix(unlist(current_result), ncol = 5, byrow = T) 
    print(result_summary)
})
save(result_summary, file = "../output/rmse_pmf.Rdata")
```

```{r}
load(file = "../output/rmse_pmf.Rdata") 

rmse_pmf <- data.frame(rbind(t(result_summary[1,,]), t(result_summary[2,,])), train_test = rep(c("Train", "Test"), each = 4), par = rep(paste("f = ", f_l[,1], ", sigma_p = ", f_l[,2], ", sigma_q = ", f_l[,3]), times = 2)) %>% gather("epoch", "RMSE", -train_test, -par)
rmse_pmf$epoch <- as.numeric(gsub("X", "", rmse_pmf$epoch))
rmse_pmf %>% ggplot(aes(x = epoch, y = RMSE, col = train_test)) + geom_point() + facet_grid(~par)
```

From the plot, we use parameters f = 10 and sigma_p=0.5 sigma_q=0.5as our basic model.

### Step 3 Postprocessing: SVD with KNN
```{r}
set.seed(0)
#get the subset of train set and test set from the first 5000 data
test_idx2 <- sample(1:5000, 5000/5, 0)
train_idx2 <- setdiff(1:5000, test_idx2)
data_train2 <- data[train_idx2,]
data_test2 <- data[test_idx2,]
```

```{r}
result <- gradesc_pmf(f = 10, sigma_p = 0.5,sigma_q = 0.5, lrate = 0.01, max.iter = 100, stopping.deriv = 0.01, data = data[1:5000,], train = data_train2, test = data_test2)
save(result, file = "../output/mat_fac_pmf.RData")
```

```{r}
load(file = "../output/mat_fac_pmf.RData")
source("../lib/KNN.R")
KNN_Rating <- KNN.post(data_train2, result) # Rating after applying KNN
Rating <- t(result$p)%*%(result$q)  # Rating without KNN
```

```{r}
RMSE <- function(rating, est_rating){
  sqr_err <- function(obs){
    sqr_error <- (obs[3] - est_rating[as.character(obs[1]), as.character(obs[2])])^2
    return(sqr_error)
  }
  return(sqrt(mean(apply(rating, 1, sqr_err))))  
}
A2_chart<-tibble(rating=c("Without KNN","With KNN"),
       train=c(RMSE(data_train2,Rating),RMSE(data_train2,KNN_Rating)),     
       test=c(RMSE(data_test2,Rating),RMSE(data_test2,KNN_Rating)))
A2_chart
```

### Step 4 Evaluation (Model Comparision)
```{r,warning=false}
#A2
RMSE <- data.frame(epochs = seq(20, 100, 20), Training_MSE = result$train_RMSE, Test_MSE = result$test_RMSE) %>% gather(key = train_or_test, value = RMSE, -epochs)
RMSE %>% ggplot(aes(x = rep(seq(20, 100, 20),2), y = RMSE,col = train_or_test)) + geom_point() + scale_x_discrete(limits = seq(20, 100, 20)) + xlim(c(0, 100))+
labs(x = "epochs",  title = "A2")
```
